{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo6VEli4yzQM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA8_BhErz67q"
      },
      "source": [
        "Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZvDmIjOzyxi"
      },
      "source": [
        "epochs = 20\n",
        "width = height = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO7tKiQ9o5KE"
      },
      "source": [
        "Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Es6eOaeyTuR"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH5l705JymIU"
      },
      "source": [
        "!kaggle datasets download -d jangedoo/utkface-new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8H5yLBBysWL"
      },
      "source": [
        "!unzip -qq utkface-new.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P5WpjB3z58-"
      },
      "source": [
        "images = [] # x\n",
        "ages = [] # y\n",
        "\n",
        "for image_name in os.listdir('crop_part1'):\n",
        "    parts = image_name.split('_')\n",
        "    ages.append(int(parts[0]))\n",
        "\n",
        "    image = cv2.imread(f'crop_part1/{image_name}')\n",
        "    image = cv2.resize(image, (width, height))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    images.append(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw34oGLU3cMN"
      },
      "source": [
        "images = pd.Series(images, name='Images')\n",
        "ages = pd.Series(ages, name='Ages')\n",
        "\n",
        "df = pd.concat([images, ages], axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VKfy2Ud5BvU"
      },
      "source": [
        "print(df['Ages'][0])\n",
        "plt.imshow(df['Images'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ycpV0e5zEA"
      },
      "source": [
        "print(df['Ages'][1])\n",
        "plt.imshow(df['Images'][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqvVphc_598X"
      },
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "plt.hist(df['Ages'], bins=df['Ages'].max())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wswb35sj1-yJ"
      },
      "source": [
        "Too many faces of people between 0 and 4 years old. The model would fit too well to these ages and not enough to the other ages. To resolve this I'm only going to include a third of the images between these ages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQKQjNCd60df"
      },
      "source": [
        "under_4 = df[df['Ages'] <= 4]\n",
        "under_4_small = under_4.sample(frac=0.3)\n",
        "\n",
        "up_4 = df[df['Ages'] > 4]\n",
        "\n",
        "df = pd.concat([under_4_small, up_4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igzwFTiR_ApH"
      },
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "plt.hist(df['Ages'], bins=df['Ages'].max())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bkq6X0M2oyX"
      },
      "source": [
        "This looks much better! The dataframe is more representative of the population now. However, there aren't many images of people over 80, which would cause the model to not train well enough on those ages. It's best to just remove over 80s and only have a model that can predict the ages of people under 80."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jj0Gmvq_BgM"
      },
      "source": [
        "df = df[df['Ages'] < 80]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGDcygn3_nXP"
      },
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "plt.hist(df['Ages'], bins=df['Ages'].max())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTr4IMpZ_yvb"
      },
      "source": [
        "X = np.array(df['Images'].values.tolist())\n",
        "Y = np.array(df['Ages'].values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ_-5JnKBmWg"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ActdB73VBypU"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, stratify=Y)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeSBMjZrCNf5"
      },
      "source": [
        "data_generator = ImageDataGenerator(rescale=1./225,\n",
        "                                    horizontal_flip=True)\n",
        "\n",
        "train_data = data_generator.flow(x_train, y_train, batch_size=32)\n",
        "val_data = data_generator.flow(x_val, y_val, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omJSNvt3pPVC"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBbrMLPvDJWn"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(width, height, 3),\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    pooling='avg'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lXj4e4zFWOS"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovb4gku7FfmP"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='relu')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuhUprVGHUv"
      },
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=Adam(learning_rate=0.001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4UYw8pFGXIb"
      },
      "source": [
        "model.fit(train_data,\n",
        "          validation_data=val_data,\n",
        "          epochs=epochs,\n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOBWeIumosJ7"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIyOKse9pk6N"
      },
      "source": [
        "!wget https://github.com/tzutalin/dlib-android/blob/master/data/shape_predictor_68_face_landmarks.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8cIgc-NFDW3"
      },
      "source": [
        "from imutils.face_utils import FaceAligner\n",
        "import imutils\n",
        "import dlib\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
        "\n",
        "\n",
        "def process_and_predict(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = imutils.resize(image, width=800)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    rects = detector(gray, 2)\n",
        "\n",
        "    for i, rect in enumerate(rects):\n",
        "        faceAligned = fa.align(image, gray, rect)\n",
        "\n",
        "        faceAligned = cv2.resize(faceAligned, (width, height))\n",
        "        faceAligned = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(faceAligned)\n",
        "\n",
        "        faceAligned = faceAligned / 255.0\n",
        "        faceAligned = np.expand_dims(faceAligned, axis=0)\n",
        "        age = model.predict(faceAligned)\n",
        "        print('Age:', int(age))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDIh2cEcJRYk"
      },
      "source": [
        "process_and_predict('/content/trump.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}